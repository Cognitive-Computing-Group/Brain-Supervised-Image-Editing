{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Brain-Supervised Image Editing\n",
    "## Supplementary Material\n",
    "### Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as sp\n",
    "import mne\n",
    "from os import listdir\n",
    "from os.path import join\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import re\n",
    "import pickle\n",
    "from tqdm.notebook import tqdm\n",
    "import sys\n",
    "\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from functools import reduce\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import mne\n",
    "import pandas as pd\n",
    "from os import listdir, path\n",
    "\n",
    "TASK_LIST = ['facecat/female','facecat/male',\n",
    "             'facecat/nosmile', 'facecat/smiles',\n",
    "             'facecat/old', 'facecat/young',\n",
    "            'facecat/blond', 'facecat/darkhaired']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Preprocessed EEG data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lzma\n",
    "file = lzma.open('data/facecat.xz', 'rb')\n",
    "db = pickle.load(file)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EEG data have already been preprocessed such that they are cleaned and segmented into epochs. An epoch corresponds to all data produced by a single stimulus viewing event. \n",
    "\n",
    "The data are structured as a large nested dictionary:\n",
    "\n",
    "Level One: 30 dictionaries, keys are integers from 0 to 29 - one for each participant in the study.\n",
    "\n",
    "Level Two: 8 dictionaries, keys are strings corresponding to task grouping and semantic feature - ['facecat/blond', 'facecat/darkhaired', 'facecat/female', 'facecat/male', 'facecat/nosmile', 'facecat/old', 'facecat/smiles', 'facecat/young']\n",
    "\n",
    "Level Three: 4 keys, keys are \"test_x\", \"test_y\", \"train_x\", \"train_y\", corresponding to the train and test set data and labels.\n",
    "\n",
    "Level Four (labels): A numpy 2D array (X, Y), where X corresponds to labels as integers 0 and 1, indicating non-target (0) and target (1) classes. Thus for \"facecat/female\", a label of 1 indicates the associated EEG data correspond to viewing a female face, whereas a label of 0 indicates the EEG data correspond to viewing a male face. Y corresponds to the specific stimuli ID/latent ID tied to the \n",
    "\n",
    "Level Four (data): A numpy.ndarray of shape (X, Y=5, Z=32). X corresponds to the epochs, Y corresponds to averaged measured EEG voltages at 0-100ms, 100-200ms, 200-300ms, 300-400ms, and 400-500ms. Z corresponds to each of the 32 channels used to record the EEG data for each epoch.\n",
    "\n",
    "Note: Due to artifact removal procedures during pre-processing (eye/head movements and other sources of noise), the size of the test and train sets varies between participants"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load in the latents used for CelebGAN generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('data/latents.pkl', 'rb')\n",
    "latents = pickle.load(file)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reshape Data so it is anonymized (100ms averages), with channel names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Results Loop\n",
    "results_dict = {}\n",
    "for user in tqdm(range(len(epos))):\n",
    "    results_dict[user] = {}\n",
    "    lda_data = epoch_to_lda_data(epos[user], times=[-0.2, 0.9])\n",
    "    \n",
    "    for task in TASK_LIST:\n",
    "        test_x = split_average(lda_data[task]['test_x'], n_split=25)\n",
    "        train_x = split_average(lda_data[task]['train_x'], n_split=25)\n",
    "        \n",
    "        train_x = train_x.reshape([train_x.shape[0], train_x.shape[1] * train_x.shape[2]])\n",
    "\n",
    "        test_y = lda_data[task]['test_y'].rel\n",
    "        train_y = lda_data[task]['train_y'].rel\n",
    "        \n",
    "        img_ids = lda_data[task]['test_y'].img\n",
    "        event_type =  lda_data[task]['test_y'].event\n",
    "        \n",
    "        lda = LDA(solver = 'lsqr', shrinkage = 'auto')\n",
    "        lda = lda.fit(train_x, list(train_y)) \n",
    "        \n",
    "        test_x = test_x.reshape([test_x.shape[0], test_x.shape[1] * test_x.shape[2]])\n",
    "        yhat = lda.predict_proba(test_x)[:,1]\n",
    "        \n",
    "        results_dict[user][task] = {\"yhat\":yhat, \"y\":test_y, \"img_id\": list(img_ids), \"event\":event_type}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sklearn.metrics.roc_auc_score(list(results_dict[0]['facecat/female']['y']), results_dict[0]['facecat/female']['yhat'], average=\"macro\", multi_class='ovo')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
