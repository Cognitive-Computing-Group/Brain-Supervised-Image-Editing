{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "prostate-assumption",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(r'home/olenikimid/Documents/PhD/GANs/progressive_growing_of_gans/')\n",
    "import pickle\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import PIL.Image\n",
    "import pickle\n",
    "import os\n",
    "# IMAGE GENERATION LOOP\n",
    "import re\n",
    "# Initialize TensorFlow session.\n",
    "tf.InteractiveSession()\n",
    "import pandas as pd\n",
    "\n",
    "TASK_LIST = ['facecat/female','facecat/male',\n",
    "             'facecat/nosmile', 'facecat/smiles',\n",
    "             'facecat/old', 'facecat/young',\n",
    "            'facecat/blond', 'facecat/darkhaired']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "individual-thousand",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "def get_available_gpus():\n",
    "    local_device_protos = device_lib.list_local_devices()\n",
    "    return [x.name for x in local_device_protos if x.device_type == 'GPU']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "residential-board",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../GANs/karras2018iclr-celebahq-1024x1024.pkl', 'rb') as file:\n",
    "    G, D, Gs = pickle.load(file)\n",
    "    # G = Instantaneous snapshot of the generator, mainly useful for resuming a previous training run.\n",
    "    # D = Instantaneous snapshot of the discriminator, mainly useful for resuming a previous training run.\n",
    "    # Gs = Long-term average of the generator, yielding higher-quality results than the instantaneous snapshot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "hourly-uzbekistan",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('results/stimuli_mapping.obj', 'rb') as file:\n",
    "    mappings = pickle.load(file)\n",
    "\n",
    "mappings.drop(['yhat', 'latent'], axis=1, inplace=True)\n",
    "\n",
    "mappings = mappings.drop_duplicates()\n",
    "\n",
    "sample_set = mappings.groupby(['task', 'user_id', 'event']).sample(1, random_state=313)\n",
    "\n",
    "tuples = [tuple(x) for x in sample_set.to_numpy()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "narrow-computer",
   "metadata": {},
   "source": [
    "# Generate Results from Brain signal SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "classical-artwork",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('results/svr_latentsV4.obj', 'rb') as file:\n",
    "    results_dict = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "sublime-investing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' \\n    neg_latents = []\\n    \\n    _latents = results_dict[user_id][task][img_id][\"NEG\"]\\n    \\n    #neg_latents.append(_latents[1])\\n    \\n    _step = np.int(np.floor(len(_latents)/5))\\n    \\n    for i in range(4):\\n        neg_latents.append(_latents[i*_step])\\n        \\n    neg_latents.append(_latents[-1])\\n    \\n    for number, latent in enumerate(neg_latents):\\n        generation_tuple.append((latent, user_id, task, \"NEG\", label, img_id, number))\\n'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generation_tuple = [] #user id, task, direction, target class, imgid, stepnumber\n",
    "for img_id, task, user_id, label in tuples:\n",
    "    \n",
    "    pos_latents = []\n",
    "    \n",
    "    _latents = results_dict[user_id][task][img_id][\"POS\"]\n",
    "    \n",
    "    #pos_latents.append(_latents[1])\n",
    "    \n",
    "    _step = np.int(np.floor(len(_latents)/5))\n",
    "    \n",
    "    for i in range(0, 4):\n",
    "        pos_latents.append(_latents[i*_step])\n",
    "        \n",
    "    pos_latents.append(_latents[-1])\n",
    "    \n",
    "    for number, latent in enumerate(pos_latents):\n",
    "        generation_tuple.append((latent, user_id, task, \"POS\", label, img_id, number))\n",
    "    \n",
    "\"\"\" \n",
    "    neg_latents = []\n",
    "    \n",
    "    _latents = results_dict[user_id][task][img_id][\"NEG\"]\n",
    "    \n",
    "    #neg_latents.append(_latents[1])\n",
    "    \n",
    "    _step = np.int(np.floor(len(_latents)/5))\n",
    "    \n",
    "    for i in range(4):\n",
    "        neg_latents.append(_latents[i*_step])\n",
    "        \n",
    "    neg_latents.append(_latents[-1])\n",
    "    \n",
    "    for number, latent in enumerate(neg_latents):\n",
    "        generation_tuple.append((latent, user_id, task, \"NEG\", label, img_id, number))\n",
    "\"\"\"     \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "tough-startup",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate dummy labels (not used by the official networks).\n",
    "labels = np.zeros([512] + Gs.input_shapes[1][1:])\n",
    "sess = tf.Session(config=tf.ConfigProto(\n",
    "      allow_soft_placement=True, log_device_placement=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "regular-appliance",
   "metadata": {},
   "outputs": [],
   "source": [
    "for latent, user_id, task, direction, label, img_id, number in generation_tuple:\n",
    "    images = Gs.run(np.array(latent.reshape(1,512)), labels)\n",
    "    images = np.clip(np.rint((images + 1.0) / 2.0 * 255.0), 0.0, 255.0).astype(np.uint8) # [-1,1] => [0,255]\n",
    "    images = images.transpose(0, 2, 3, 1) # NCHW => NHWC\n",
    "    taskname = re.sub('/', '_', task)\n",
    "    PIL.Image.fromarray(images[0], 'RGB').save(f\"results/generated/{user_id}-{taskname}-{label}-{img_id}-{number}-0.jpg\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "harmful-binary",
   "metadata": {},
   "source": [
    "# Generate Results from Explicit Ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "perceived-perfume",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('results/svr_latents_Explicit.obj', 'rb') as file:\n",
    "    results_dict = pickle.load(file)\n",
    "    \n",
    "generation_tuple = [] #user id, task, direction, target class, imgid, stepnumber\n",
    "for img_id, task, user_id, label in tuples:\n",
    "    \n",
    "    pos_latents = []\n",
    "    \n",
    "    _latents = results_dict[user_id][task][img_id][\"POS\"]\n",
    "    \n",
    "    #pos_latents.append(_latents[1])\n",
    "    \n",
    "    _step = np.int(np.floor(len(_latents)/5))\n",
    "    \n",
    "    for i in range(0, 4):\n",
    "        pos_latents.append(_latents[i*_step])\n",
    "        \n",
    "    pos_latents.append(_latents[-1])\n",
    "    \n",
    "    for number, latent in enumerate(pos_latents):\n",
    "        generation_tuple.append((latent, user_id, task, \"POS\", label, img_id, number))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "superior-affect",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate dummy labels (not used by the official networks).\n",
    "labels = np.zeros([512] + Gs.input_shapes[1][1:])\n",
    "sess = tf.Session(config=tf.ConfigProto(\n",
    "      allow_soft_placement=True, log_device_placement=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "activated-messaging",
   "metadata": {},
   "outputs": [],
   "source": [
    "for latent, user_id, task, direction, label, img_id, number in generation_tuple:\n",
    "    images = Gs.run(np.array(latent.reshape(1,512)), labels)\n",
    "    images = np.clip(np.rint((images + 1.0) / 2.0 * 255.0), 0.0, 255.0).astype(np.uint8) # [-1,1] => [0,255]\n",
    "    images = images.transpose(0, 2, 3, 1) # NCHW => NHWC\n",
    "    taskname = re.sub('/', '_', task)\n",
    "    PIL.Image.fromarray(images[0], 'RGB').save(f\"results/generated/{user_id}-{taskname}-{label}-{img_id}-{number}-1.jpg\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stable-enclosure",
   "metadata": {},
   "source": [
    "# Generate Results from Random SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "permanent-organizer",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('results/svr_latents_Random.obj', 'rb') as file:\n",
    "    results_dict = pickle.load(file)\n",
    "     \n",
    "generation_tuple = [] #user id, task, direction, target class, imgid, stepnumber\n",
    "for img_id, task, user_id, label in tuples:\n",
    "    \n",
    "    pos_latents = []\n",
    "    \n",
    "    _latents = results_dict[user_id][task][img_id][\"POS\"]\n",
    "    \n",
    "    #pos_latents.append(_latents[1])\n",
    "    \n",
    "    _step = np.int(np.floor(len(_latents)/5))\n",
    "    \n",
    "    for i in range(0, 4):\n",
    "        pos_latents.append(_latents[i*_step])\n",
    "        \n",
    "    pos_latents.append(_latents[-1])\n",
    "    \n",
    "    for number, latent in enumerate(pos_latents):\n",
    "        generation_tuple.append((latent, user_id, task, \"POS\", label, img_id, number))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "southwest-canberra",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate dummy labels (not used by the official networks).\n",
    "labels = np.zeros([512] + Gs.input_shapes[1][1:])\n",
    "sess = tf.Session(config=tf.ConfigProto(\n",
    "      allow_soft_placement=True, log_device_placement=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "subtle-crack",
   "metadata": {},
   "outputs": [],
   "source": [
    "for latent, user_id, task, direction, label, img_id, number in generation_tuple:\n",
    "    images = Gs.run(np.array(latent.reshape(1,512)), labels)\n",
    "    images = np.clip(np.rint((images + 1.0) / 2.0 * 255.0), 0.0, 255.0).astype(np.uint8) # [-1,1] => [0,255]\n",
    "    images = images.transpose(0, 2, 3, 1) # NCHW => NHWC\n",
    "    taskname = re.sub('/', '_', task)\n",
    "    PIL.Image.fromarray(images[0], 'RGB').save(f\"results/generated/{user_id}-{taskname}-{label}-{img_id}-{number}-2.jpg\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "living-there",
   "metadata": {},
   "source": [
    "# Generate Results from Random Gaussian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "seven-quantum",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('results/random_gaussian.obj', 'rb') as file:\n",
    "    results_dict = pickle.load(file)\n",
    "    \n",
    "generation_tuple = [] #user id, task, direction, target class, imgid, stepnumber\n",
    "for img_id, task, user_id, label in tuples:\n",
    "    \n",
    "    pos_latents = []\n",
    "    \n",
    "    _latents = results_dict[user_id][task][img_id][\"POS\"]\n",
    "    \n",
    "    #pos_latents.append(_latents[1])\n",
    "    \n",
    "    _step = np.int(np.floor(len(_latents)/5))\n",
    "    \n",
    "    for i in range(0, 4):\n",
    "        pos_latents.append(_latents[i*_step])\n",
    "        \n",
    "    pos_latents.append(_latents[-1])\n",
    "    \n",
    "    for number, latent in enumerate(pos_latents):\n",
    "        generation_tuple.append((latent, user_id, task, \"POS\", label, img_id, number))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ruled-gather",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate dummy labels (not used by the official networks).\n",
    "labels = np.zeros([512] + Gs.input_shapes[1][1:])\n",
    "sess = tf.Session(config=tf.ConfigProto(\n",
    "      allow_soft_placement=True, log_device_placement=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "dutch-arizona",
   "metadata": {},
   "outputs": [],
   "source": [
    "for latent, user_id, task, direction, label, img_id, number in generation_tuple:\n",
    "    images = Gs.run(np.array(latent.reshape(1,512)), labels)\n",
    "    images = np.clip(np.rint((images + 1.0) / 2.0 * 255.0), 0.0, 255.0).astype(np.uint8) # [-1,1] => [0,255]\n",
    "    images = images.transpose(0, 2, 3, 1) # NCHW => NHWC\n",
    "    taskname = re.sub('/', '_', task)\n",
    "    PIL.Image.fromarray(images[0], 'RGB').save(f\"results/generated/{user_id}-{taskname}-{label}-{img_id}-{number}-3.jpg\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "religious-thickness",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
